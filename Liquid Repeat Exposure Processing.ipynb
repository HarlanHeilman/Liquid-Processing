{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "966139dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    import toolkit\n",
    "    import numpy as np\n",
    "    import ipywidgets as widgets\n",
    "    from astropy.io import fits\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "except ImportError:\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install --user --upgrade matplotlib pandas astropy numpy shutil pathlib tkinter tqdm ipympl ipywidgets\n",
    "    print('Restart you kernel and try again')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a21b7c34",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "General process outline \n",
    "1. Chose a parent data directory\n",
    "2. Run the `processing()` function. This will do the following things\n",
    "    1. This starts by sorting files what have the `\"Repeat\"` keyword based on their directory. This should also just go ahead and sort the files based on their name into sub directories but I have not done that yet.\n",
    "    2. Next, the sorted fits files are loaded into `FitsLoader` type objects that allows them to be averaged and saved together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed81c4cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b1154f8d2e341f68075010213c5ee9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b021aec15026431abc103b678f0b56e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "directory = toolkit.file_dialog()\n",
    "liquid_data = toolkit.processing(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1dcc89a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2aba688d6b94b579d984811e0aff875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='sample', options=('P123_PTX_Escan',), value='P123_PTX_Escan'), Outâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib ipympl\n",
    "\n",
    "@widgets.interact(sample=liquid_data.keys())\n",
    "def show_plots(sample):\n",
    "    \n",
    "    @widgets.interact(energy=liquid_data[sample].keys())\n",
    "    def check_process(energy):\n",
    "        liquid_data[sample][energy].im_show()\n",
    "        liquid_data[sample][energy].im_show_avg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d38453a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting toolkit.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile toolkit.py \n",
    "# Uncomment to edit or just edit in the .py file\n",
    "\n",
    "import copy\n",
    "import glob\n",
    "import os\n",
    "from typing import Union\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "from shutil import copy2, rmtree\n",
    "from astropy.io import fits\n",
    "\n",
    "from pathlib import Path\n",
    "from tkinter import filedialog\n",
    "from tkinter import *\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\"\"\"\n",
    "Ya know that whole dont repeat yourself thing.... yeah that went out the window... this whole thing can and should be refactored for readability and to improve speed\n",
    "\"\"\"\n",
    "\n",
    "#\n",
    "# Helpful functions\n",
    "# These are stored in my toolkit.py file so maybe they should have their own .py file\n",
    "#\n",
    "\n",
    "\n",
    "def file_dialog():\n",
    "    root = Tk()\n",
    "    root.withdraw()\n",
    "    directory = Path(filedialog.askdirectory())\n",
    "    return directory\n",
    "\n",
    "\n",
    "def open_dialog():\n",
    "    root = Tk()\n",
    "    root.withdraw()\n",
    "    file_save_path = Path(filedialog.askopenfilename())\n",
    "    return file_save_path if file_save_path else None\n",
    "\n",
    "\n",
    "def fits_copy_rename(file_path: Path | str, rename: str):\n",
    "    dest_path, ext = (\n",
    "        \".\".join(str(file_path).split(\".\")[:-1]),\n",
    "        str(file_path).split(\".\")[-1],\n",
    "    )\n",
    "    dest_file_name = Path(f\"{dest_path}{rename}.{ext}\")\n",
    "    copy2(Path(file_path), dest_file_name)\n",
    "\n",
    "    return dest_file_name\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Added near the end. Need to go back though and remove redundant fits reading \n",
    "    \"\n",
    "    with fits.open(file) as header:\n",
    "        ...\n",
    "    \"\n",
    "And replace them with FitsLoader(directory) using properties and method calls to\n",
    "populate variables. \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class FitsLoader:\n",
    "    \"\"\"\n",
    "    A clone of the xrr fits loader. This loads a fits file unpacking the header.... should be used more and allot of the sorting should just use this object as base.\n",
    "    But for now it is only used in the processing. This should also be updated to remove redundancies such as those from getting the scan name.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, directory: Path):\n",
    "        self.directory = directory\n",
    "        self.image_data = []\n",
    "        self.energy = []\n",
    "        self._shutter = []\n",
    "\n",
    "        self._read_files()\n",
    "        self.bright_dark_mask = np.array([not bool(status) for status in self._shutter])\n",
    "\n",
    "        # process methods\n",
    "        self._merge_data()\n",
    "        self._write_merged_file()\n",
    "\n",
    "    def _read_files(self):\n",
    "        self.file_list = sorted(glob.glob(os.path.join(self.directory, \"*.fits\")))\n",
    "        self.names = [Path(file).name for file in self.file_list]\n",
    "        arrays = [\n",
    "            [\n",
    "                fits.getheader(f, 0)[\"Beamline Energy\"],\n",
    "                fits.getheader(f, 0)[\"CCD Camera Shutter Inhibit\"],\n",
    "            ]\n",
    "            for f in self.file_list\n",
    "        ]\n",
    "        self.energies, self._shutter = np.column_stack(arrays)\n",
    "\n",
    "        self.image_data = np.squeeze(\n",
    "            np.array([[fits.getdata(f, 2) for f in self.file_list]])\n",
    "        ).astype(np.uint16)\n",
    "\n",
    "    def _merge_data(self):\n",
    "        \"\"\"Uses the boolean shutter status to mask the images data and average\"\"\"\n",
    "        bright_images = self.image_data[self.bright_dark_mask]\n",
    "        dark_images = self.image_data[np.invert(self.bright_dark_mask)]\n",
    "\n",
    "        self.averaged_bright = bright_images.mean(axis=0, dtype=np.uint16)\n",
    "        self.averaged_dark = dark_images.mean(axis=0, dtype=np.uint16)\n",
    "\n",
    "    def _write_merged_file(self):\n",
    "        \"\"\"\n",
    "        In general this whole thing is really bad practice if something goes wrong the files are never closed.... NOT GOOD\n",
    "        \"\"\"\n",
    "\n",
    "        dark_copy_to = fits_copy_rename(self.file_list[0], rename=\"Dark_Average\")\n",
    "        bright_copy_to = fits_copy_rename(self.file_list[0], rename=\"Bright_Average\")\n",
    "\n",
    "        dark_fits = copy.deepcopy(fits.open(self.file_list[0]))\n",
    "        bright_fits = copy.deepcopy(fits.open(self.file_list[1]))\n",
    "\n",
    "        dark_fits[2].data = self.averaged_dark  # type: ignore\n",
    "        bright_fits[2].data = self.averaged_bright  # type: ignore\n",
    "\n",
    "        dark_fits.writeto(dark_copy_to, overwrite=True)\n",
    "        bright_fits.writeto(bright_copy_to, overwrite=True)\n",
    "\n",
    "    def im_show(self) -> None:\n",
    "        dim = round(self.energies.size / 2, 0)\n",
    "        kw = {\"cmap\": \"hot\", \"norm\": colors.LogNorm()}\n",
    "\n",
    "        fig, axes = plt.subplots(ncols=int(dim), nrows=2, figsize=(20, 5))\n",
    "        for i, ax in enumerate(np.ravel(axes)):\n",
    "            if i <= len(self.image_data) - 1:\n",
    "                ax.imshow(self.image_data[i], **kw)\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def im_show_avg(self) -> None:\n",
    "        kw = {\"cmap\": \"hot\", \"norm\": colors.LogNorm()}\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "        ax1.imshow(self.averaged_bright, **kw)\n",
    "        ax1.set_title(\"Averaged Bright\")\n",
    "        ax1.set_xticks([])\n",
    "        ax1.set_yticks([])\n",
    "\n",
    "        ax2.imshow(self.averaged_dark, **kw)\n",
    "        ax2.set_title(\"Averaged Dark\")\n",
    "        ax2.set_xticks([])\n",
    "        ax2.set_yticks([])\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "#\n",
    "# Basic Fits File Sorting\n",
    "# This should probably be split to make its own .py file for readability... something like file_structure.py...\n",
    "#\n",
    "\n",
    "\n",
    "def path_factory(path: Path) -> None:\n",
    "    \"\"\"\n",
    "    factory for making paths. If the requested path does not exist, it makes it. This can now be used if we make classes of inputs allowing for dynamic data trees based on user input.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : Path\n",
    "        pathlib object describing the requested path\n",
    "    \"\"\"\n",
    "\n",
    "    if not path.exists():\n",
    "        path.mkdir()\n",
    "\n",
    "\n",
    "def liquid_filter(file_path: Path, indicator: str = \"Repeat\") -> bool:\n",
    "    \"\"\"filter function definition\"\"\"\n",
    "    file_name = file_path.name\n",
    "    if file_name.find(indicator) != -1:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def get_files(dir: Path, filter_func=liquid_filter) -> list[Path]:\n",
    "    \"\"\"wrapper function to get the files in a directory\"\"\"\n",
    "    file_list = list(dir.iterdir())\n",
    "    return list(filter(filter_func, file_list))\n",
    "\n",
    "\n",
    "def get_sample_name(full_path: Path) -> str:\n",
    "    \"\"\"Wrapper function to get the file name as a string form path object\"\"\"\n",
    "    file = full_path.name\n",
    "    file_name = file.split(\".\")[0]\n",
    "    return file_name.split(\"Repeat\")[0]\n",
    "\n",
    "\n",
    "# These would then be dynamically generated\n",
    "def sorted_dir(dir: Path, fresh: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Generates the sorted directory away from the data collected directory.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dir : Path\n",
    "        path to the top level data\n",
    "    \"\"\"\n",
    "\n",
    "    p_dir = dir.parent\n",
    "    Directories = [x[0] for x in os.walk(p_dir)]\n",
    "\n",
    "    sort_path = p_dir / \"Sorted\"\n",
    "    if fresh and sort_path.exists():\n",
    "        rmtree(sort_path)\n",
    "\n",
    "    path_factory(sort_path)\n",
    "\n",
    "\n",
    "def sample_dir(data_dir: Path, destination: Path | None = None) -> None:\n",
    "    \"\"\"\n",
    "    Parses the sample name from the data_dir and generates a new subfolder in the destination for future sorting.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_dir : Path\n",
    "        Directory with the data located in it\n",
    "    destination : Path, optional\n",
    "        Destination folder where each sub directory will be generated, by default None signifying the destination path as\n",
    "            >>> destination = data_dir / 'Sorted'\n",
    "    \"\"\"\n",
    "    if destination == None:\n",
    "        destination = data_dir.parent / \"Sorted\"\n",
    "\n",
    "    file_names = get_files(data_dir)\n",
    "    sample_names = [get_sample_name(file) for file in file_names]\n",
    "\n",
    "    for sample in sample_names:\n",
    "        sample_path = destination / sample\n",
    "        path_factory(sample_path)\n",
    "\n",
    "\n",
    "def file_tree_factory(dir: Path, fresh: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Makes a new directory for the sorted data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dir : pathlib.Path\n",
    "        Directory of the data that you want sorted\n",
    "    \"\"\"\n",
    "\n",
    "    sorted_dir(dir, fresh=fresh)\n",
    "    sample_dir(dir)\n",
    "    return\n",
    "\n",
    "\n",
    "def file_filter(fits_files: list, filter=\"Repeat\") -> list:\n",
    "    \"\"\"\n",
    "    A bad method of filtering the fits files. Should implement with filter() but it doesn't matter\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fits_files : list\n",
    "        list of fits files\n",
    "    filter : str, optional\n",
    "        indicator string to start filtering, by default 'Repeat'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        list of files with the filter indicator\n",
    "    \"\"\"\n",
    "    return [fits_file for fits_file in fits_files if fits_file.name.find(filter) != -1]\n",
    "\n",
    "\n",
    "def energy_sorter(files: list, sort_dir: Path) -> None:\n",
    "    \"\"\"\n",
    "    Energy sorter\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    files : list\n",
    "        List of files that will be sorted by energy\n",
    "    sort_dir : Path\n",
    "        destination directory that the files will be sorted into\n",
    "    \"\"\"\n",
    "\n",
    "    for file in tqdm(files):\n",
    "        new_en = fits.getheader(file, 0)[\"Beamline Energy\"]\n",
    "\n",
    "        destination = sort_dir / get_sample_name(file) / str(round(new_en, 1))\n",
    "        path_factory(destination)\n",
    "        copy2(file, destination)\n",
    "\n",
    "\n",
    "def liquid_sorter(directory: Path, filter=\"Repeat\", fresh: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Collects the energies each fits was collected at and makes subfolder for each energy\n",
    "    Generates a dictionary containing the current file location, and its destination.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dir : pathlib.Path\n",
    "        Directory of the data that you want sorted\n",
    "    \"\"\"\n",
    "\n",
    "    assert directory.name == \"CCD\"\n",
    "    file_tree_factory(directory, fresh=fresh)\n",
    "\n",
    "    fits_files = list(directory.glob(\"*fits\"))\n",
    "    repeat_files = file_filter(fits_files, filter=\"Repeat\")\n",
    "    sort_dir = directory.parent / \"Sorted\"\n",
    "\n",
    "    energy_sorter(repeat_files, sort_dir)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "#\n",
    "# Main process\n",
    "# This should also be sorted into its own .py file for readability... Something like liquid_processing.py... feel free to swap things to CammelCased whenever you want to\n",
    "#\n",
    "\n",
    "\n",
    "def processing(directory: Path, filter=\"Repeat\") -> dict:\n",
    "    \"\"\"\n",
    "    General processing function for sorting fits files based on their energy and sample name.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    directory : Path\n",
    "        Directory of the total data\n",
    "    filter : str, optional\n",
    "        Indicator string pointing to the data that needs to be filtered out, by default 'Repeat'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    liquid_data: dict\n",
    "        liquid data as fits files packed into a dictionary. The dictionary structure is based on\n",
    "        {\n",
    "            sample_name: {\n",
    "                energy: Loaded Fits Data,\n",
    "                ...\n",
    "            },\n",
    "            ...\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    assert directory.name == \"CCD\"\n",
    "\n",
    "    liquid_data = {}\n",
    "    liquid_sorter(directory, filter=filter)\n",
    "\n",
    "    sorted_path = directory.parent / \"Sorted\"\n",
    "    samples = list(sorted_path.iterdir())\n",
    "    liquid_data = {}\n",
    "\n",
    "    for sample in samples:\n",
    "        energies = list(sample.iterdir())\n",
    "        liquid_data[sample.name] = {\n",
    "            energy.name: FitsLoader(energy) for energy in tqdm(energies)\n",
    "        }\n",
    "\n",
    "    return liquid_data\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     directory = file_dialog()\n",
    "#     liquid_data = processing(directory)\n",
    "#     A = 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fbfa7a28",
   "metadata": {},
   "source": [
    "# Your old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab69a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The standard fare:\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "# Recall our use of this module to work with FITS files in Lab 4:\n",
    "from astropy.io import fits \n",
    "\n",
    "# This lets us use various Unix (or Unix-like) commands within Python:\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d123d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbaec30",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd Washington State University (email.wsu.edu)\\Carbon Lab Research Group - Documents\\Synchrotron Logistics and Data\\ALS - Berkeley\\Data\\BL1101\\2023May\\Liquid\\10 May\\Sorted Repeat\\288.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c1f2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = os.listdir() # Makes a list of all the .FITS files in the current directory\n",
    "number_of_files = len(all_files) # Counts the number of files in 'all_files'\n",
    "\n",
    "# Sets the total dark and total image as .FITS files with all the same attributes as the\n",
    "# first dark or image in the directory.\n",
    "dark_total = fits.open(all_files[0])\n",
    "image_total = fits.open(all_files[1]) # first dark or image in the directory.\n",
    "\n",
    "# change data type\n",
    "dark_total[2].data = np.float64(dark_total[2].data)\n",
    "image_total[2].data = np.float64(image_total[2].data)\n",
    "\n",
    "# The files alternate between image and dark. This will loops through all the files in the directory summing the data accociated\n",
    "# with the images and darks of each file.\n",
    "for i in range(2, number_of_files-1, 2):\n",
    "    image = fits.open(all_files[i]) # Next file to be added to the sum\n",
    "    dark = fits.open(all_files[i+1])\n",
    "    \n",
    "    image[2].data = np.float64(image[2].data) # change data type\n",
    "    dark[2].data = np.float64(dark[2].data)\n",
    "    \n",
    "    dark_total[2].data += dark[2].data # Add next set of data to total image\n",
    "    image_total[2].data += image[2].data\n",
    "\n",
    "    \n",
    "# Rescale so it can be changed back to int16\n",
    "# change data type\n",
    "dark_total[2].data = dark_total[2].data*(65000/400000)\n",
    "image_total[2].data = image_total[2].data*(65000/400000)\n",
    "dark_total[2].data = np.uint16(dark_total[2].data)\n",
    "image_total[2].data = np.uint16(image_total[2].data)\n",
    "\n",
    "# Following two lines writes out a new .FITS file with the summed image and dark data. The headers of these files are the same\n",
    "# as the headers of the first image and dark in the current directory. :: fits.writeto('out.fits', darksub) # save output\n",
    "\n",
    "image_total.writeto('Pluronic_PTX_Repeat_sum_80842-00036.fits')\n",
    "dark_total.writeto('Pluronic_PTX_Repeat_sum_80842-00037.fits')\n",
    "\n",
    "image_total.info()\n",
    "print(image_total[2].header)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,20)) # Side-by-side plots of the summed image and dark\n",
    "ax1.imshow(image_total[2].data)\n",
    "ax2.imshow(dark_total[2].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea448f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7.5))\n",
    "plt.imshow(image_total[2].data)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9563b73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7.5))\n",
    "plt.imshow(dark_total[2].data)\n",
    "plt.colorbar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "966139dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    import toolkit\n",
    "    import numpy as np\n",
    "    from astropy.io import fits\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "except ImportError:\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install --user --upgrade matplotlib pandas astropy numpy shutil pathlib tkinter tqdm\n",
    "    print('Restart you kernel and try again')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a21b7c34",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "General process outline \n",
    "1. Chose a parent data directory\n",
    "2. Run the `processing()` function. This will do the following things\n",
    "    1. This starts by sorting files what have the `\"Repeat\"` keyword based on their directory. This should also just go ahead and sort the files based on their name into sub directories but I have not done that yet.\n",
    "    2. Next, the sorted fits files are loaded into `FitsLoader` type objects that allows them to be averaged and saved together. \n",
    "3. To average and save the files you will want to access the following methods \n",
    "    - `liquid_data[\"energy\"].merge_data()`: This computes the average bright and dark image\n",
    "    - `liquid_data[\"energy\"].write_merged_file()`: This writes a destination file based on the merged image\n",
    "\n",
    "## Notes and further work\n",
    "Further work needs to be done to fix three important issues \n",
    "- Currently, the fits object is generated with all of the data so long as the file name has 'Repeat' in it and it shares the same energy. This needs to be updated so that separate fits objects are constructed for each sample in a given energy. \n",
    "    - This could be updated by simply altering the `processing()` function such that the dictionary keys are changed from `energy.name` to `sample_name + energy.name` where `sample_name` can be pulled by something like `file.name.split(\"Repeat\")[0]`.\n",
    "- The mask should be based on `dark = False`, `bright = True`. Right now this is not the case.\n",
    "    - A simple fix would be to force every mask into a structure of `mask = [False, True, ... , True, False]` of a desired length.\n",
    "- For some dumb reason the mask itself is not applying to the self.images array... this should not happen.\n",
    "    - A possible solution would be to force the the images out of being a numpy array and into a list of numpy arrays. This mixed object type is a 1d sequence that can be sliced with a working mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dc2fb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# toy_fits = toolkit.open_dialog()\n",
    "# header = fits.open(toy_fits)[0].header\n",
    "# del header['COMMENT']\n",
    "# meta = {item: header[item] for item in header}\n",
    "# import json \n",
    "\n",
    "# with open('test2.json', 'w') as fp:\n",
    "#     json.dump(meta, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed81c4cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'with_suffix'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m directory \u001b[39m=\u001b[39m toolkit\u001b[39m.\u001b[39mfile_dialog()\n\u001b[1;32m----> 2\u001b[0m liquid_data \u001b[39m=\u001b[39m toolkit\u001b[39m.\u001b[39;49mprocessing(directory)\n",
      "File \u001b[1;32mc:\\Users\\Harlan Heilman\\Washington State University (email.wsu.edu)\\Carbon Lab Research Group - Documents (1)\\Devin Grabner\\Data\\Micelle Project\\toolkit.py:202\u001b[0m, in \u001b[0;36mprocessing\u001b[1;34m(directory, filter)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocessing\u001b[39m(directory: Path, \u001b[39mfilter\u001b[39m \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mRepeat\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m:\n\u001b[0;32m    201\u001b[0m     liquid_data \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 202\u001b[0m     liquid_sorter(directory,\u001b[39mfilter\u001b[39;49m \u001b[39m=\u001b[39;49m \u001b[39mfilter\u001b[39;49m)\n\u001b[0;32m    204\u001b[0m     sorted_path \u001b[39m=\u001b[39m directory\u001b[39m.\u001b[39mparent \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mSorted\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    205\u001b[0m     energies \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(sorted_path\u001b[39m.\u001b[39miterdir())\n",
      "File \u001b[1;32mc:\\Users\\Harlan Heilman\\Washington State University (email.wsu.edu)\\Carbon Lab Research Group - Documents (1)\\Devin Grabner\\Data\\Micelle Project\\toolkit.py:189\u001b[0m, in \u001b[0;36mliquid_sorter\u001b[1;34m(directory, filter)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[39mCollects the energies each fits was collected at and makes subfolder for each energy\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \u001b[39mGenerates a dictionary containing the current file location, and its destination.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[39m    Directory of the data that you want sorted\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[39massert\u001b[39;00m directory\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mCCD\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 189\u001b[0m check_parent(directory)\n\u001b[0;32m    191\u001b[0m fits_files \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(directory\u001b[39m.\u001b[39mglob(\u001b[39m\"\u001b[39m\u001b[39m*fits\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m    192\u001b[0m repeat_files \u001b[39m=\u001b[39m file_filter(fits_files, \u001b[39mfilter\u001b[39m \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mRepeat\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Harlan Heilman\\Washington State University (email.wsu.edu)\\Carbon Lab Research Group - Documents (1)\\Devin Grabner\\Data\\Micelle Project\\toolkit.py:109\u001b[0m, in \u001b[0;36mcheck_parent\u001b[1;34m(dir)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[39mMakes a new directory for the sorted data\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[39m    Directory of the data that you want sorted\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    108\u001b[0m p_dir \u001b[39m=\u001b[39m \u001b[39mdir\u001b[39m\u001b[39m.\u001b[39mparent\n\u001b[1;32m--> 109\u001b[0m sample_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(p_dir\u001b[39m.\u001b[39;49mglob(\u001b[39m\"\u001b[39;49m\u001b[39m*fits\u001b[39;49m\u001b[39m\"\u001b[39;49m))\u001b[39m.\u001b[39;49mwith_suffix(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    110\u001b[0m Directories \u001b[39m=\u001b[39m [x[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mwalk(p_dir)]\n\u001b[0;32m    112\u001b[0m sort_path \u001b[39m=\u001b[39m p_dir \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSorted\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'with_suffix'"
     ]
    }
   ],
   "source": [
    "directory = toolkit.file_dialog()\n",
    "liquid_data = toolkit.processing(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1dcc89a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method FitsLoader.merge_data of <toolkit.FitsLoader object at 0x0000029AB76CA6E0>>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liquid_data['270.0'].merge_data\n",
    "liquid_data['270.0'].write_merged_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d38453a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting toolkit.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile toolkit.py\n",
    "import copy\n",
    "import glob\n",
    "import os\n",
    "from typing import Union\n",
    "import numpy as np\n",
    "from shutil import copy2\n",
    "from astropy.io import fits\n",
    "\n",
    "from pathlib import Path\n",
    "from tkinter import filedialog\n",
    "from tkinter import *\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#\n",
    "# Helpful functions\n",
    "#\n",
    "\n",
    "\n",
    "def file_dialog():\n",
    "    root = Tk()\n",
    "    root.withdraw()\n",
    "    directory = Path(filedialog.askdirectory())\n",
    "    return directory\n",
    "\n",
    "def open_dialog():\n",
    "    root = Tk()\n",
    "    root.withdraw()\n",
    "    file_save_path = Path(filedialog.askopenfilename())\n",
    "    return file_save_path if file_save_path else None\n",
    "\n",
    "'''\n",
    "Added near the end. Need to go back though and remove redundant fits reading \n",
    "    \"\n",
    "    with fits.open(file) as header:\n",
    "        ...\n",
    "    \"\n",
    "'''\n",
    "\n",
    "class FitsLoader:\n",
    "    '''\n",
    "    A clone of the xrr fits loader. This loads a fits file unpacking the header \n",
    "    '''\n",
    "    def __init__(self, directory: Path):\n",
    "        self.directory = directory\n",
    "        self.images = []\n",
    "        self.energy = []\n",
    "        self._shutter = []\n",
    "\n",
    "        self._read_files()\n",
    "        self.bright_dark_mask = np.array([not bool(status) for status in self._shutter])\n",
    "        self.merge_data()\n",
    "\n",
    "\n",
    "    def _read_files(self):\n",
    "        self.file_list = sorted(glob.glob(os.path.join(self.directory, \"*.fits\")))\n",
    "        self.scan_name = self.file_list[0].split(\"\\\\\")[-1].split(\"-\")[0]\n",
    "        \n",
    "        arrays = [\n",
    "            [\n",
    "                fits.getheader(f, 0)[\"Beamline Energy\"],\n",
    "                fits.getheader(f, 0)[\"CCD Camera Shutter Inhibit\"]\n",
    "            ]\n",
    "            for f in self.file_list\n",
    "        ]\n",
    "        self.energies, self._shutter = np.column_stack(arrays)\n",
    "\n",
    "        self.image_data = np.squeeze(\n",
    "            np.array([[fits.getdata(f, 2) for f in self.file_list]])\n",
    "        ).astype(np.uint16)\n",
    "\n",
    "\n",
    "    def merge_data(self):\n",
    "        '''Uses the boolean shutter status to mask the images data and average'''\n",
    "        bright_images = self.images[self.bright_dark_mask]\n",
    "        dark_images = self.images[np.invert(self.bright_dark_mask)]\n",
    "\n",
    "        self.averaged_bright = bright_images.mean(axis = 0, dtype = np.uint16)\n",
    "        self.averaged_dark = bright_images.mean(axis = 0, dtype = np.uint16)\n",
    "\n",
    "    def write_merged_file(self):\n",
    "        dark_fits = copy.deepcopy(fits.open(self.file_list[0]))\n",
    "        bright_fits = copy.deepcopy(fits.open(self.file_list[1]))\n",
    "\n",
    "        dark_out_file = self.file_list[0].slice('-')[:-2] + 'Dark_Average'\n",
    "        bright_out_file = self.file_list[0].slice('-')[:-2] + 'Bright_Average'\n",
    "\n",
    "        dark_fits[2].data = self.averaged_dark\n",
    "        bright_fits[2].data = self.averaged_bright\n",
    "\n",
    "        dark_fits.writeto(dark_out_file, overwrite = True)\n",
    "        bright_fits.writeto(bright_out_file, overwrite = True)\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# Basic Fits File Sorting\n",
    "#\n",
    "\n",
    "def check_parent(dir: Path) -> None:\n",
    "    \"\"\"\n",
    "    Makes a new directory for the sorted data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dir : pathlib.Path\n",
    "        Directory of the data that you want sorted\n",
    "    \"\"\"\n",
    "    p_dir = dir.parent\n",
    "    sample_list = list(p_dir.glob(\"*txt\"))\n",
    "    Directories = [x[0] for x in os.walk(p_dir)]\n",
    "\n",
    "    sort_path = p_dir / \"Sorted\"\n",
    "    sample_path = sort_path / sample_list\n",
    "    \n",
    "    if not sort_path.exists():\n",
    "        sort_path.mkdir()\n",
    "    else:\n",
    "        print(\n",
    "            \"The sorted directory already exists - Checking for energy sub-directories\"\n",
    "        )\n",
    "    \n",
    "    for sample in sample_path:\n",
    "        if not sample.exists():\n",
    "            sample.mkdir()\n",
    "        else:\n",
    "            print(\n",
    "                \"The sorted directory already exists - Checking for energy sub-directories\"\n",
    "            )\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def file_filter(fits_files: list, filter = 'Repeat') -> list:\n",
    "    '''\n",
    "    A bad method of filtering the fits files. Should implement with filter() but it doesn't matter\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fits_files : list\n",
    "        list of fits files\n",
    "    filter : str, optional\n",
    "        indicator string to start filtering, by default 'Repeat'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        list of files with the filter indicator\n",
    "    '''\n",
    "    return [fits_file for fits_file in fits_files if fits_file.name.find(filter) != -1]\n",
    "\n",
    "\n",
    "def energy_sorter(files: list, sort_dir: Path) -> None:\n",
    "    '''\n",
    "    Energy sorter\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    files : list\n",
    "        List of files that will be sorted by energy\n",
    "    sort_dir : Path\n",
    "        destination directory that the files will be sorted into\n",
    "    '''\n",
    "    for i, file in tqdm(enumerate(files)):\n",
    "        with fits.open(file) as headers:\n",
    "            new_en = round(headers[0].header[49], 1)\n",
    "    \n",
    "        dest = sort_dir / str(new_en)\n",
    "    \n",
    "        if not dest.exists():\n",
    "            dest.mkdir()\n",
    "    \n",
    "        copy2(file, dest)\n",
    "\n",
    "\n",
    "def liquid_sorter(directory: Path, filter = 'Repeat') -> None:\n",
    "    \"\"\"\n",
    "    Collects the energies each fits was collected at and makes subfolder for each energy\n",
    "    Generates a dictionary containing the current file location, and its destination.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dir : pathlib.Path\n",
    "        Directory of the data that you want sorted\n",
    "    \"\"\"\n",
    "\n",
    "    assert directory.name == 'CCD'\n",
    "    check_parent(directory)\n",
    "\n",
    "    fits_files = list(directory.glob(\"*fits\"))\n",
    "    repeat_files = file_filter(fits_files, filter = 'Repeat')\n",
    "    sort_dir = directory.parent / \"Sorted\"\n",
    "\n",
    "    energy_sorter(repeat_files, sort_dir)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def processing(directory: Path, filter = 'Repeat') -> dict:\n",
    "    liquid_data = {}\n",
    "    liquid_sorter(directory,filter = filter)\n",
    "\n",
    "    sorted_path = directory.parent / 'Sorted'\n",
    "    energies = list(sorted_path.iterdir())\n",
    "    liquid_data = {energy.name: FitsLoader(energy) for energy in tqdm(energies)}\n",
    "    return liquid_data\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fbfa7a28",
   "metadata": {},
   "source": [
    "# Your old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab69a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The standard fare:\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "# Recall our use of this module to work with FITS files in Lab 4:\n",
    "from astropy.io import fits \n",
    "\n",
    "# This lets us use various Unix (or Unix-like) commands within Python:\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d123d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbaec30",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd Washington State University (email.wsu.edu)\\Carbon Lab Research Group - Documents\\Synchrotron Logistics and Data\\ALS - Berkeley\\Data\\BL1101\\2023May\\Liquid\\10 May\\Sorted Repeat\\288.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c1f2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = os.listdir() # Makes a list of all the .FITS files in the current directory\n",
    "number_of_files = len(all_files) # Counts the number of files in 'all_files'\n",
    "\n",
    "# Sets the total dark and total image as .FITS files with all the same attributes as the\n",
    "# first dark or image in the directory.\n",
    "dark_total = fits.open(all_files[0])\n",
    "image_total = fits.open(all_files[1]) # first dark or image in the directory.\n",
    "\n",
    "# change data type\n",
    "dark_total[2].data = np.float64(dark_total[2].data)\n",
    "image_total[2].data = np.float64(image_total[2].data)\n",
    "\n",
    "# The files alternate between image and dark. This will loops through all the files in the directory summing the data accociated\n",
    "# with the images and darks of each file.\n",
    "for i in range(2, number_of_files-1, 2):\n",
    "    image = fits.open(all_files[i]) # Next file to be added to the sum\n",
    "    dark = fits.open(all_files[i+1])\n",
    "    \n",
    "    image[2].data = np.float64(image[2].data) # change data type\n",
    "    dark[2].data = np.float64(dark[2].data)\n",
    "    \n",
    "    dark_total[2].data += dark[2].data # Add next set of data to total image\n",
    "    image_total[2].data += image[2].data\n",
    "\n",
    "    \n",
    "# Rescale so it can be changed back to int16\n",
    "# change data type\n",
    "dark_total[2].data = dark_total[2].data*(65000/400000)\n",
    "image_total[2].data = image_total[2].data*(65000/400000)\n",
    "dark_total[2].data = np.uint16(dark_total[2].data)\n",
    "image_total[2].data = np.uint16(image_total[2].data)\n",
    "\n",
    "# Following two lines writes out a new .FITS file with the summed image and dark data. The headers of these files are the same\n",
    "# as the headers of the first image and dark in the current directory. :: fits.writeto('out.fits', darksub) # save output\n",
    "\n",
    "image_total.writeto('Pluronic_PTX_Repeat_sum_80842-00036.fits')\n",
    "dark_total.writeto('Pluronic_PTX_Repeat_sum_80842-00037.fits')\n",
    "\n",
    "image_total.info()\n",
    "print(image_total[2].header)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,20)) # Side-by-side plots of the summed image and dark\n",
    "ax1.imshow(image_total[2].data)\n",
    "ax2.imshow(dark_total[2].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea448f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7.5))\n",
    "plt.imshow(image_total[2].data)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9563b73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7.5))\n",
    "plt.imshow(dark_total[2].data)\n",
    "plt.colorbar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
